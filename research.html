
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="shortcut icon" href="nudt.ico">
    <link rel="stylesheet" type="text/css" href="style.css" />
    <!-- <link rel="shortcut icon" href="paper_dragon.ico"> -->
    <title>Chenping Hou's Research</title>
    <base href="https://chenpinghou.github.io/index.html">
    <!-- <base href="./index.html"> -->

</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Chenping Hou</h1><hr>
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="groups.html">Group</a></div>
<!--<div class="menu-item"><a href="talks.html">Talks</a></div> -->
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<!--<div class="menu-item"><a href="service.html">Service</a></div>-->
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="grants.html">Grants</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="code.html">Codes & Data</a></div>
<!--<div class="menu-item"><a href="award.html">Awards & honours</a></div>-->
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Selected Research Topics</h1> <!-- 相关研究方向总结 -->
        <h2><hr></a>这里可以总结一些实验室的研究课题</h2>
        <!-- <h2><hr></a>Learning with noisy labels</h2>
        Learning with noisy labels becomes a more and more important topic recently. The reason is that, in the era of big data, datasets are becoming larger and larger. Often, large-scale datasets are infeasible to be annotated accurately due to the cost and time, which naturally brings us cheap datasets with noisy labels. However, the noisy dataset can severally degenerate the performance of machine learning models, especially for the deep neural networks, as they easily memorize and eventually fit label noise. Normally, there are two ways to deal with label noise. One is to extract confident examples, whose labels are correct with a high probability. Another one is to model the noise and then get rid of the side-effect of label noise, i.e., obtain the optimal classifier defined by the clean data by exploiting the noisy data. 
   <h3>Topics:</h3>
  <ul>
              
         <li><p>Learning under instance-dependent label noise</p></li>
        <li><p>Estimate the label noise transition matrix without using anchor points </p></li>
        <li><p>Estimate the label noise transition matrix by using anchor points</p></li>
       <li><p>Exploiting the memorization effect of deep neural networks</p></li>
        <li><p>Deep representation learning under label noise </p></li>
       <li><p>Learning with noisy similarity labels </p></li>
        <li><p>Learning with complementary labels</p></li>
        <li><p>Learning with group noise </p></li>
        <li><p>Harnessing side information for classification under label noise </p></li>
        <li><p>Dealing with label noise in the face recognition problem </p></li>
       </ul> -->

        

    
</td>
</tr>
</table>
</body>
</html>
